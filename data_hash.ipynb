{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step through process of data generation, salt creation, hash generation and search method for string matching in a stepped down environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protected environment\n",
    "The protected environment contains data that cannot be distributed into less well controlled information or physical spaces.  Activities involving source data all occur within an environment that has the required controls for the confidentiality needs of the data, and also the management and maintenance of the salt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, string, hashlib, json\n",
    "\n",
    "salt_version = 0\n",
    "salt_dict = []\n",
    "coarse_names = {}\n",
    "fine_names = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a data set\n",
    "As an example create a dataset that you wish to be able to validate against where some of the data is concrete (such as name) and some of the data has increasing fidelity such as date of birth or addresses.  Create a dataset that consists of a name (concrete) and an address (variable) based on three fields, city, street and number.  \n",
    "\n",
    "The dataset can be any source format but needs to be reliablly extracted with strict formatting rules between search input and record storage (case, handling spaces and hyphenating, language specific characters, unknown values, date ranges etc).\n",
    "\n",
    "Data that is not protected can also be stored unhashed to provide an indication of how you managed to match.  In this example it is the origin of the name and a reference for the entry.  An entry reference could be used to compare or extract data from other sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 person records loaded.\n"
     ]
    }
   ],
   "source": [
    "person_data = {'100001': ['mouse', 'mickey', 'orlando', 'main street', '30', 'DISNEY'],\n",
    "        '100002': ['Duck', 'Donald', 'ducksville', '13th street', '1313', 'DISNEY'],\n",
    "        '100003': ['Duck', 'Don', 'ducksville', '13th street', '1313', 'DISNEY'], # Entry represents a name alternative\n",
    "        '100004': ['Kent', 'Clark', 'new york', 'unknown', 'unknown', 'MARVEL'],\n",
    "        '100005': ['Kent', 'Clark', 'new york', 'clinton street', '344', 'MARVEL'], # This is a coarse clash but not fine clash\n",
    "        '100006': ['Kent', 'Clark', 'metropolis', 'unknown', 'unknown', 'MARVEL'], # Entry represents alternative city\n",
    "        '100007': ['Kent', 'Clark', 'new york', 'clinton street', '344', 'WARNER BROS.']} # Multiple production entries on a single person entry \n",
    "\n",
    "print ('{person_data_size} person records loaded.'.format(person_data_size=len(person_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salt Generation\n",
    "Generate a salt through a sufficiently random routine and store it alongside an identifier, (date, version or other factor).  For simplicity this system only stores a single 16 character salt and attaches to a version as a key:value pair.  The salt has to be managed within the protected environment but will have to be used in stepped down environments in order to create the search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created salt maDHSiTuiVd4U8ah as salt version 1.\n"
     ]
    }
   ],
   "source": [
    "salt = ''.join(random.SystemRandom().choice(string.ascii_uppercase + string.digits + string.ascii_lowercase) for _ in range(16))\n",
    "salt_version += 1\n",
    "salt_dict.append({salt_version: salt})\n",
    "\n",
    "print('Created salt {salt_string} as salt version {salt_version}.'.format(salt_string=salt, \n",
    "                                                                           salt_version=salt_version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate single record data entry.\n",
    "Define a schema for joining data and then store as a new data set.  In this example each row level record is constructed as two different sets to allow course and fine grained matching;\n",
    "- Fine grained consists as name and full address \n",
    "- Course grained consists of name with just city\n",
    "\n",
    "Each record is then combined with the versioned salt to prevent some common attack methods, such as dictionary attacks and rainbow tables.  The salt ultimately prevents the record from being tested with name and location data in the event it is acquired by someone wishing to validate where all the superheros live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created fine grained (6 records) and coarse grained (5 records) data sets using salt version 1\n"
     ]
    }
   ],
   "source": [
    "coarse_names = {}\n",
    "fine_names = {}\n",
    "salt_used = salt\n",
    "salt_used_version = salt_version\n",
    "\n",
    "for entry_id, name_record in person_data.items():\n",
    "    # Create a string of the data to be matched against\n",
    "    fine_record = '{surname}:{firstname}:{city}:{street}:{house_number}:{salt}'.format(surname=name_record[0].lower(),\n",
    "                                                                              firstname=name_record[1].lower(),\n",
    "                                                                              city=name_record[2],\n",
    "                                                                              street=name_record[3],\n",
    "                                                                              house_number=name_record[4],\n",
    "                                                                              salt=salt)\n",
    "    \n",
    "    coarse_record = '{surname}:{firstname}:{city}:{salt}'.format(surname=name_record[0].lower(),\n",
    "                                                                              firstname=name_record[1].lower(),\n",
    "                                                                              city=name_record[2],\n",
    "                                                                              salt=salt)\n",
    "    \n",
    "    # Create the hashed versions of the search strings\n",
    "    fine_record_hash = hashlib.sha3_512(bytes(fine_record, 'utf-8')).hexdigest()\n",
    "    coarse_record_hash = hashlib.sha3_512(bytes(coarse_record, 'utf-8')).hexdigest()\n",
    "    \n",
    "    # Add to a dictionary of hashes related to entry_id and the entry_type\n",
    "    try:\n",
    "        fine_names[fine_record_hash].append((entry_id, name_record[5]))\n",
    "    except KeyError:\n",
    "        fine_names[fine_record_hash] = [(entry_id, name_record[5])]\n",
    "    \n",
    "    try:\n",
    "        coarse_names[coarse_record_hash].append((entry_id, name_record[5]))\n",
    "    except KeyError:\n",
    "        coarse_names[coarse_record_hash] = [(entry_id, name_record[5])]\n",
    "    \n",
    "print('Created fine grained ({fine_len} records) and \\\n",
    "coarse grained ({coarse_len} records) data \\\n",
    "sets using salt version {salt_used}'.format(fine_len=len(fine_names), coarse_len=len(coarse_names), salt_used=salt_used_version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashed data sets and versioned salt\n",
    "Two data sets are created for distribution and represent a coarse and a fine grained exact string match capability, **without containing the original data**.  The use of the salt prevents reconstruction of the original entries by trying name and address data, something that could be done if the format of the original string construction is known and the data set is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashing Information:\n",
      "Version: 1 \n",
      "Salt: maDHSiTuiVd4U8ah\n",
      "\n",
      "Original Data Set:\n",
      "{\"100001\": [\"mouse\", \"mickey\", \"orlando\", \"main street\", \"30\", \"DISNEY\"], \"100002\": [\"Duck\", \"Donald\", \"ducksville\", \"13th street\", \"1313\", \"DISNEY\"], \"100003\": [\"Duck\", \"Don\", \"ducksville\", \"13th street\", \"1313\", \"DISNEY\"], \"100004\": [\"Kent\", \"Clark\", \"new york\", \"unknown\", \"unknown\", \"MARVEL\"], \"100005\": [\"Kent\", \"Clark\", \"new york\", \"clinton street\", \"344\", \"MARVEL\"], \"100006\": [\"Kent\", \"Clark\", \"metropolis\", \"unknown\", \"unknown\", \"MARVEL\"], \"100007\": [\"Kent\", \"Clark\", \"new york\", \"clinton street\", \"344\", \"WARNER BROS.\"]}\n",
      "\n",
      "Coarse Grained Data Set: \n",
      "{\"51901981075923a58f77b1d6fe364d9c04fc04699cfb60d8d6e65a059f5aa3e14bb0ced2735b38a0111d625cdefa515f966ee5bd273f36fcc18fe9fca92a1caa\": [[\"100001\", \"DISNEY\"]], \"1e296f559ad90597d7e6866552eb930f4bd0f76ac8bb1fbc1bfbeb1b0cb3d31690851b36cdbe88ba266ea6764a565eb9ad202e7c65fb7b90dd78b4ec6d1712b1\": [[\"100002\", \"DISNEY\"]], \"c681e0d5e1aaa39be4206755daa469f62417b619a80702326c09efe03eeb94b7c1527f38491b5dcf07844ee8650b7e73cebf2a47d23c048726ab1b7d7e03b0f5\": [[\"100003\", \"DISNEY\"]], \"92f556172da5d3dc12a98d65e9923060e2e28f7eca57b3144703842e65efb9eaa2b2d42efd5986bfc998ed3311763a96c875859a5bc0598de6dba1850acd9b4b\": [[\"100004\", \"MARVEL\"], [\"100005\", \"MARVEL\"], [\"100007\", \"WARNER BROS.\"]], \"ad7f43c9f545e4dc8f9ab717c393738cb74fc71acd4b3bb6f0675b5ce56e9d7a609c7f5a7d02e30f8a280883bb25ad1c8edf8df58e42368fb7868eefe581b36c\": [[\"100006\", \"MARVEL\"]]}\n",
      "\n",
      "Fine Grained Data Set: \n",
      "{\"b3005b6dce6579bf03f8ade729fd119c4c5dec0471dbd3245d06db28c1e550f2ffaf36557a538f8236537c748f1903465e55e83df1502a6b72c49f20b4ccd5c0\": [[\"100001\", \"DISNEY\"]], \"f4be3f3d4b77ae0cf0671b23e069685ced0bdb1f046b081f8da81b2f935e168c45aed8b06df29ade2ecd3a4b66d2d8989f2d944baee3ac8881120776a99afde0\": [[\"100002\", \"DISNEY\"]], \"b955b4a1d4ff4566bf8ac558ba0c8fa1118bf54bd3dad65a05317b4757c84a96d9261ee00a5f6f86f6b162a77e2393841d19b664c11b8df7290e2f4e47952a5a\": [[\"100003\", \"DISNEY\"]], \"4f15b97cdb9b841d0e84a4a4e28026fbea419cd8f971c0c009e85ac06b5b864bbd26bfbc2ad1b6b6178a391d90df0ae95130d1fd67d15b4dd2c3f3bdb2c7f3ac\": [[\"100004\", \"MARVEL\"]], \"51f135bc0808b85e3ab6cc93439d00c8e0d26c0b42dc35efa034d91218e8971588789212bb68de6afaa3616ca16a890e0a3b0ed288bf372c3b11406c0c77de35\": [[\"100005\", \"MARVEL\"], [\"100007\", \"WARNER BROS.\"]], \"6a12b831915bd17079e2f74ef5d3302a07c7b6e4b1f11aed956dca22051b63f653bda1dc6c54f5d9aa8844ca0536dee7ecdba5f0b60a3b7aecaa95ce85adeccf\": [[\"100006\", \"MARVEL\"]]}\n"
     ]
    }
   ],
   "source": [
    "# Hashing Information\n",
    "print('Hashing Information:\\nVersion: {salt_version} \\nSalt: {salt}\\n'.format(salt_version=salt_used_version, salt=salt_used))\n",
    "\n",
    "# Original Data Set\n",
    "print('Original Data Set:\\n{original_data}\\n'.format(original_data=json.dumps(person_data)))\n",
    "\n",
    "# Coarse Data Set\n",
    "print('Coarse Grained Data Set: \\n{coarse_json}\\n'.format(coarse_json=json.dumps(coarse_names)))\n",
    "\n",
    "# Fine Grained Data Set\n",
    "print('Fine Grained Data Set: \\n{fine_json}'.format(fine_json=json.dumps(fine_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stepped Down Environment\n",
    "\n",
    "### Salt Management\n",
    "The data entering a stepped down environment consists only of hashed data.  In order to be able to construct a searchable string you will also require the salt, however, the salt needs to be protected to prevent brute force data washing.  Suggestions in a live deployment to protect the salt;\n",
    "- Centralise the storage of the salt as it is extracted out from the protected environment and only distribute when you need to use it.\n",
    "- Implement a symetric key encryption of the salt, enabling distribution while protecting through encryption and then break glass the symentric key.\n",
    "The salt should not exist on disk within the search client, once it has been entered as part of enabling search then it should **only** be stored in memory.\n",
    "\n",
    "### Data Distribution\n",
    "The hashed data needs to be distributed to the search end point, while this could involve payload encryption in flight it may not be necessary if sufficient controls exist within the transport layer.  The data may benefit from being encrypted within the application to prevent data loss through compromise of the operating system but depends on existing controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salt to be used (default = V1 maDHSiTuiVd4U8ah): \n",
      "Surname to be searched (default=Kent): \n",
      "Firstname to be searched (default=Clark): \n",
      "Address (house,street,city) (default=344,Clinton Street,New York): \n"
     ]
    }
   ],
   "source": [
    "salt_in = input('Salt to be used (default = V{last_salt_version} {last_salt}): '.format(last_salt=salt, last_salt_version=salt_version)) or salt\n",
    "surname_in = input('Surname to be searched (default=Kent): ') or 'Kent'\n",
    "firstname_in = input('Firstname to be searched (default=Clark): ') or 'Clark'\n",
    "address_in = input('Address (house,street,city) (default=344,Clinton Street,New York): ') or '344,Clinton Street,New York'\n",
    "\n",
    "address = address_in.split(',')\n",
    "city = address[2].lower()\n",
    "street = address[1].lower()\n",
    "house_number = address[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the search string and hash\n",
    "The search string has to be constructed exactly the same way as the format when it was created in the protected environment.  The salt is then added, concatenated and hashed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse Search: kent:clark:new york:maDHSiTuiVd4U8ah \n",
      "Coarse Hash: 92f556172da5d3dc12a98d65e9923060e2e28f7eca57b3144703842e65efb9eaa2b2d42efd5986bfc998ed3311763a96c875859a5bc0598de6dba1850acd9b4b\n",
      " \n",
      "Fine Search: kent:clark:new york:clinton street:344:maDHSiTuiVd4U8ah \n",
      "Fine Hash: 51f135bc0808b85e3ab6cc93439d00c8e0d26c0b42dc35efa034d91218e8971588789212bb68de6afaa3616ca16a890e0a3b0ed288bf372c3b11406c0c77de35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_fine = '{surname}:{firstname}:{city}:{street}:{house_number}:{salt}'.format(surname=surname_in.lower(),\n",
    "                                                                          firstname=firstname_in.lower(),\n",
    "                                                                          city=city,\n",
    "                                                                          street=street,\n",
    "                                                                          house_number=house_number,\n",
    "                                                                          salt=salt_in)\n",
    "search_coarse = '{surname}:{firstname}:{city}:{salt}'.format(surname=surname_in.lower(),\n",
    "                                                           firstname=firstname_in.lower(),\n",
    "                                                           city=city,\n",
    "                                                           salt=salt_in)\n",
    "\n",
    "hash_coarse = hashlib.sha3_512(bytes(search_coarse, 'utf-8')).hexdigest()\n",
    "hash_fine = hashlib.sha3_512(bytes(search_fine, 'utf-8')).hexdigest()\n",
    "\n",
    "print('Coarse Search: {coarse} \\nCoarse Hash: {hash_coarse}\\n \\\n",
    "\\nFine Search: {fine} \\nFine Hash: {hash_fine}\\n'.format(coarse=search_coarse, \n",
    "                                                      fine=search_fine,\n",
    "                                                      hash_coarse=hash_coarse,\n",
    "                                                      hash_fine=hash_fine))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Results\n",
    "The hash is used to search both the coarse and fine grained hash data sets.  If an identity match is found then the entry_id and other related information is returned.  \n",
    "**Note:** Matches that are exact will also appear in the coarse data set.  Could add logic to remove matching entry_ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found following exact (fine grained) matches:\n",
      "[[\"100005\", \"MARVEL\"], [\"100007\", \"WARNER BROS.\"]]\n",
      "\n",
      "Found following broad (coarse grained) matches:\n",
      "[[\"100004\", \"MARVEL\"], [\"100005\", \"MARVEL\"], [\"100007\", \"WARNER BROS.\"]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    found_coarse = coarse_names[hash_coarse]\n",
    "except:\n",
    "    found_coarse = 'No matches found'   \n",
    "try:\n",
    "    found_fine = fine_names[hash_fine]\n",
    "except:\n",
    "    found_fine = 'No matches found'\n",
    "\n",
    "\n",
    "print('Found following exact (fine grained) matches:\\n{fine_results}\\n'.format(fine_results=json.dumps(found_fine)))\n",
    "print('Found following broad (coarse grained) matches:\\n{coarse_results}\\n'.format(coarse_results=json.dumps(found_coarse)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
